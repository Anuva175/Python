{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2SS9+FSYoAMlXkhRVNzoZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","spark=SparkSession.builder\\\n","    .appName(\"Day21\")\\\n","    .getOrCreate()"],"metadata":{"id":"FQbYeKzvdZtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"233TydVpagS3","executionInfo":{"status":"ok","timestamp":1766466705177,"user_tz":-330,"elapsed":45,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}}},"outputs":[],"source":["data = [\n","    (\"ORD001\",\"Delhi\",\"Laptop\",45000),\n","    (\"ORD002\",\"Mumbai\",\"Mobile\",32000),\n","    (\"ORD003\",\"Bangalore\",\"Laptop\",52000),\n","    (\"ORD004\",\"Delhi\",\"Tablet\",28000),\n","    (\"ORD005\",\"Mumbai\",\"Laptop\",61000),\n","    (\"ORD006\",\"Chennai\",\"Mobile\",30000),\n","    (\"ORD007\",\"Delhi\",\"Laptop\",47000),\n","    (\"ORD008\",\"Bangalore\",\"Tablet\",35000),\n","    (\"ORD009\",\"Mumbai\",\"Laptop\",58000),\n","    (\"ORD010\",\"Delhi\",\"Mobile\",29000)\n","]\n","\n","columns = [\"order_id\",\"city\",\"product\",\"amount\"]\n","\n","df = spark.createDataFrame(data, columns)\n","\n"]},{"cell_type":"code","source":["high_value_df=df.filter(df.amount>30000)"],"metadata":{"id":"4pVPTZ41ckKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["high_value_df.count()\n","high_value_df.groupBy(\"city\").sum(\"amount\").show()\n","high_value_df.groupBy(\"product\").avg(\"amount\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jig4fNsecuzS","executionInfo":{"status":"ok","timestamp":1766464057128,"user_tz":-330,"elapsed":10625,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"86f0dfbb-bec1-4591-8493-e2311dc91b6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+-----------+\n","|     city|sum(amount)|\n","+---------+-----------+\n","|Bangalore|      87000|\n","|   Mumbai|     151000|\n","|    Delhi|      92000|\n","+---------+-----------+\n","\n","+-------+-----------+\n","|product|avg(amount)|\n","+-------+-----------+\n","| Laptop|    52600.0|\n","| Mobile|    32000.0|\n","| Tablet|    35000.0|\n","+-------+-----------+\n","\n"]}]},{"cell_type":"code","source":["high_value_df.cache()\n","high_value_df.count()\n","high_value_df.groupBy(\"city\").sum(\"amount\").show()\n","high_value_df.groupBy(\"product\").avg(\"amount\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fy8-iWmLc8xi","executionInfo":{"status":"ok","timestamp":1766464062989,"user_tz":-330,"elapsed":2644,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"54167113-28b5-49a3-ccc4-db5dc57ea5d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+-----------+\n","|     city|sum(amount)|\n","+---------+-----------+\n","|Bangalore|      87000|\n","|   Mumbai|     151000|\n","|    Delhi|      92000|\n","+---------+-----------+\n","\n","+-------+-----------+\n","|product|avg(amount)|\n","+-------+-----------+\n","| Laptop|    52600.0|\n","| Mobile|    32000.0|\n","| Tablet|    35000.0|\n","+-------+-----------+\n","\n"]}]},{"cell_type":"code","source":["\n","high_value_df.unpersist()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZ09GfQ-dKrl","executionInfo":{"status":"ok","timestamp":1766464196254,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"4167f83c-d48c-4d11-e144-20546564f02c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[order_id: string, city: string, product: string, amount: bigint]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df=df.filter(df.amount>30000).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"gtEpxr2SgkGu","executionInfo":{"status":"error","timestamp":1766465353488,"user_tz":-330,"elapsed":30,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"b8b203fe-f480-4cad-ef18-e84621e18918"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'filter'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3986516947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'filter'"]}]},{"cell_type":"code","source":["sales_data = [\n","    (\"TXN001\",\"Delhi \",\"Laptop\",\"Electronics\",\"45000\",\"2024-01-05\",\"Completed\"),\n","    (\"TXN002\",\"Mumbai\",\"Mobile \",\"electronics\",\"32000\",\"05/01/2024\",\"Completed\"),\n","    (\"TXN003\",\"Bangalore\",\"Tablet\",\" Electronics \",\"30000\",\"2024/01/06\",\"Completed\"),\n","    (\"TXN004\",\"Delhi\",\"Laptop\",\"Electronics\",\"\",\"2024-01-07\",\"Cancelled\"),\n","    (\"TXN005\",\"Chennai\",\"Mobile\",\"Electronics\",\"invalid\",\"2024-01-08\",\"Completed\"),\n","    (\"TXN006\",\"Mumbai\",\"Tablet\",\"Electronics\",None,\"2024-01-08\",\"Completed\"),\n","    (\"TXN007\",\"Delhi\",\"Laptop\",\"electronics\",\"45000\",\"09-01-2024\",\"Completed\"),\n","    (\"TXN008\",\"Bangalore\",\"Mobile\",\"Electronics\",\"28000\",\"2024-01-09\",\"Completed\"),\n","    (\"TXN009\",\"Mumbai\",\"Laptop\",\"Electronics\",\"55000\",\"2024-01-10\",\"Completed\"),\n","    (\"TXN009\",\"Mumbai\",\"Laptop\",\"Electronics\",\"55000\",\"2024-01-10\",\"Completed\")\n","]\n","customer_data = [\n","(\"C001\",\"Delhi\",\"Premium\"),\n","(\"C002\",\"Mumbai\",\"Standard\"),\n","(\"C003\",\"Bangalore\",\"Premium\"),\n","(\"C004\",\"Chennai\",\"Standard\"),\n","(\"C005\",\"Mumbai\",\"Premium\")\n","]\n","city_lookup = [\n","(\"Delhi\",\"Tier-1\"),\n","(\"Mumbai\",\"Tier-1\"),\n","(\"Bangalore\",\"Tier-1\"),\n","(\"Chennai\",\"Tier-2\")\n","]\n"],"metadata":{"id":"3PZAqbhVgqR2","executionInfo":{"status":"ok","timestamp":1766466712426,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType,FloatType\n","sales_schema=StructType([\n","    StructField(\"order_id\",StringType(),True),\n","    StructField(\"city\",StringType(),True),\n","    StructField(\"product\",StringType(),True),\n","    StructField(\"category\",StringType(),True),\n","    StructField(\"amount\",StringType(),True),\n","    StructField(\"order_date\",StringType(),True),\n","    StructField(\"status\",StringType(),True)\n","])\n","customer_schema=StructType([\n","    StructField(\"customer_id\",StringType(),True),\n","    StructField(\"city\",StringType(),True),\n","    StructField(\"customer_type\",StringType(),True)\n","])\n","cities_schema=StructType([\n","    StructField(\"city\",StringType(),True),\n","    StructField(\"tier\",StringType(),True)\n","])\n","salesdf=spark.createDataFrame(data=sales_data,schema=sales_schema)\n","salesdf.show()\n","customerdf=spark.createDataFrame(data=customer_data,schema=customer_schema)\n","customerdf.show()\n","citiesdf=spark.createDataFrame(data=city_lookup,schema=cities_schema)\n","citiesdf.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amMCCWO6luyv","executionInfo":{"status":"ok","timestamp":1766467771630,"user_tz":-330,"elapsed":2950,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"46a8c22d-7cd4-4998-d14c-43bd4114f300"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+---------+-------+-------------+-------+----------+---------+\n","|order_id|     city|product|     category| amount|order_date|   status|\n","+--------+---------+-------+-------------+-------+----------+---------+\n","|  TXN001|   Delhi | Laptop|  Electronics|  45000|2024-01-05|Completed|\n","|  TXN002|   Mumbai|Mobile |  electronics|  32000|05/01/2024|Completed|\n","|  TXN003|Bangalore| Tablet| Electronics |  30000|2024/01/06|Completed|\n","|  TXN004|    Delhi| Laptop|  Electronics|       |2024-01-07|Cancelled|\n","|  TXN005|  Chennai| Mobile|  Electronics|invalid|2024-01-08|Completed|\n","|  TXN006|   Mumbai| Tablet|  Electronics|   NULL|2024-01-08|Completed|\n","|  TXN007|    Delhi| Laptop|  electronics|  45000|09-01-2024|Completed|\n","|  TXN008|Bangalore| Mobile|  Electronics|  28000|2024-01-09|Completed|\n","|  TXN009|   Mumbai| Laptop|  Electronics|  55000|2024-01-10|Completed|\n","|  TXN009|   Mumbai| Laptop|  Electronics|  55000|2024-01-10|Completed|\n","+--------+---------+-------+-------------+-------+----------+---------+\n","\n","+-----------+---------+-------------+\n","|customer_id|     city|customer_type|\n","+-----------+---------+-------------+\n","|       C001|    Delhi|      Premium|\n","|       C002|   Mumbai|     Standard|\n","|       C003|Bangalore|      Premium|\n","|       C004|  Chennai|     Standard|\n","|       C005|   Mumbai|      Premium|\n","+-----------+---------+-------------+\n","\n","+---------+------+\n","|     city|  tier|\n","+---------+------+\n","|    Delhi|Tier-1|\n","|   Mumbai|Tier-1|\n","|Bangalore|Tier-1|\n","|  Chennai|Tier-2|\n","+---------+------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","salesdf=salesdf.withColumn(\"amount\",F.expr(\"try_cast(amount as int)\")).withColumn(\"order_date\",F.to_date(\"order_date\",\"yyyy-MM-dd\"))\n"],"metadata":{"id":"h0ttdpnfotRq","executionInfo":{"status":"ok","timestamp":1766467309706,"user_tz":-330,"elapsed":55,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["invalid_df=salesdf.filter(\n","    F.col(\"amount\").isNull()|\n","    F.col(\"order_date\").isNull()|\n","    (~F.col(\"status\").isin(\"Completed\",\"Pending\"))\n",")\n","valid_df=salesdf.subtract(invalid_df)"],"metadata":{"id":"jYi-qtQ0qCFn","executionInfo":{"status":"ok","timestamp":1766467516357,"user_tz":-330,"elapsed":114,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["df=df.withColumn(\"city\",F.trim(F.col(\"city\")))\\\n","   .withColumn(\"product\",F.trim(F.col(\"product\")))"],"metadata":{"id":"yfos9J95q0NR","executionInfo":{"status":"ok","timestamp":1766467667464,"user_tz":-330,"elapsed":147,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["df=df.withColumn(\"category\",F.upper(F.col(\"category\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"DcH4eqRDrZG7","executionInfo":{"status":"error","timestamp":1766467935744,"user_tz":-330,"elapsed":232,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"6348f461-e20f-4dce-ba92-8b4e51f967d4"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["{\"ts\": \"2025-12-23 05:32:17.244\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`amount`, `city`, `order_id`, `product`]. SQLSTATE: 42703\", \"context\": {\"file\": \"line 1 in cell [36]\", \"line\": \"\", \"fragment\": \"col\", \"errorClass\": \"UNRESOLVED_COLUMN.WITH_SUGGESTION\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o719.withColumn.\\n: org.apache.spark.sql.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`amount`, `city`, `order_id`, `product`]. SQLSTATE: 42703;\\n'Project [order_id#429, city#576, product#487, amount#432L, 'upper('category) AS category#577]\\n+- Project [order_id#429, upper(city#486) AS city#576, product#487, amount#432L]\\n   +- Project [order_id#429, city#486, trim(product#431, None) AS product#487, amount#432L]\\n      +- Project [order_id#429, trim(city#430, None) AS city#486, product#431, amount#432L]\\n         +- LogicalRDD [order_id#429, city#430, product#431, amount#432L], false\\n\\n\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\tat scala.util.Try$.apply(Try.scala:217)\\n\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\\n\\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\\n\\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\\n\\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\\n\\tat org.apache.spark.sql.classic.Dataset.withPlan(Dataset.scala:2263)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:1283)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumns(Dataset.scala:232)\\n\\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2187)\\n\\tat org.apache.spark.sql.classic.Dataset.withColumn(Dataset.scala:1819)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\\n\\t\\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)\\n\\t\\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)\\n\\t\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)\\n\\t\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)\\n\\t\\tat scala.collection.immutable.List.foreach(List.scala:334)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:299)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)\\n\\t\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\\n\\t\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\\n\\t\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\\n\\t\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\\n\\t\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\\n\\t\\tat scala.util.Try$.apply(Try.scala:217)\\n\\t\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\\n\\t\\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\\n\\t\\t... 23 more\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/usr/local/lib/python3.12/dist-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"]},{"output_type":"error","ename":"AnalysisException","evalue":"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`amount`, `city`, `order_id`, `product`]. SQLSTATE: 42703;\n'Project [order_id#429, city#576, product#487, amount#432L, 'upper('category) AS category#577]\n+- Project [order_id#429, upper(city#486) AS city#576, product#487, amount#432L]\n   +- Project [order_id#429, city#486, trim(product#431, None) AS product#487, amount#432L]\n      +- Project [order_id#429, trim(city#430, None) AS city#486, product#431, amount#432L]\n         +- LogicalRDD [order_id#429, city#430, product#431, amount#432L], false\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2818594341.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1621\u001b[0m                 \u001b[0mmessageParameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"arg_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"col\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             )\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mParentDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `category` cannot be resolved. Did you mean one of the following? [`amount`, `city`, `order_id`, `product`]. SQLSTATE: 42703;\n'Project [order_id#429, city#576, product#487, amount#432L, 'upper('category) AS category#577]\n+- Project [order_id#429, upper(city#486) AS city#576, product#487, amount#432L]\n   +- Project [order_id#429, city#486, trim(product#431, None) AS product#487, amount#432L]\n      +- Project [order_id#429, trim(city#430, None) AS city#486, product#431, amount#432L]\n         +- LogicalRDD [order_id#429, city#430, product#431, amount#432L], false\n"]}]},{"cell_type":"code","source":["df=df.withColumn(\"amount\",F.expr(\"try_cast(amount as int)\")).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"i8RWU7LLsm0z","executionInfo":{"status":"error","timestamp":1766468221535,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"37a33a89-e567-4cd5-cbf4-fcbbc6cae987"},"execution_count":45,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'withColumn'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2465803150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amount\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"try_cast(amount as int)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'withColumn'"]}]},{"cell_type":"code","source":["df=df.filter(F.col(\"amount\").isNotNull()&(F.col(\"amount\")>0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"iX9biCJSsxJA","executionInfo":{"status":"error","timestamp":1766468191483,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"e7d246ea-dee7-4208-dc97-5c6a968bfdbb"},"execution_count":42,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'filter'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-51289679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'filter'"]}]},{"cell_type":"code","source":["df=df.withColumn(\n","    \"order_date\",\n","    F.coalesce(\n","        F.to_date(\"order_date\",\"yyyy-MM-dd\"),\n","        F.to_date(\"order_date\",\"dd-MM-yyyy\"),\n","        F.to_date(\"order_date\",\"MM/dd/yyyy\")\n","    )\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Zzt1Wy74tBB1","executionInfo":{"status":"error","timestamp":1766468175204,"user_tz":-330,"elapsed":63,"user":{"displayName":"Anuvarsini A","userId":"11249603367073252026"}},"outputId":"4f505ff4-d775-4f9c-a5ee-c777b7464fd3"},"execution_count":41,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'withColumn'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-458562482.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df=df.withColumn(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"order_date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     F.coalesce(\n\u001b[1;32m      4\u001b[0m         \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"order_date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"yyyy-MM-dd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"order_date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dd-MM-yyyy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'withColumn'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PQoKo5zptkec"},"execution_count":null,"outputs":[]}]}